{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pypico\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "from astropy.cosmology import LambdaCDM\n",
    "import emcee\n",
    "import corner\n",
    "import os\n",
    "import imageio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (WMAP, PICO, SNe Ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the wmap satellite CMB data\n",
    "wmap = np.loadtxt('wmap_tt_spectrum_9yr_v5.txt')\n",
    "multipole = wmap[:,0] \n",
    "power = wmap[:,1] \n",
    "errPower = wmap[:,2]\n",
    "\n",
    "#Load the pico training data\n",
    "pico = pypico.load_pico(\"jcset_py3.dat\")\n",
    "\n",
    "#Load the SNe Ia data\n",
    "sn_z,sn_dm,sn_dm_err = np.loadtxt(\"SCPUnion2.1_mu_vs_z.txt\",delimiter=\"\\t\",skiprows=5, usecols = (1,2,3),unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Probability Function for WMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PICO_spectrum(pars):\n",
    "    \"\"\"\n",
    "    Function to evaluate the CAMB model emulator for a given set of parameters. \n",
    "    Much faster than the full CAMB model\n",
    "    \n",
    "    Input:\n",
    "        pars (arr)- model parameters\n",
    "        \n",
    "    Output:\n",
    "        tt (arr)- power spectrum values as a function of multipole moment \n",
    "            according to a pico model with the given parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    H0, ombh2, omch2, omk, tau, As, ns, alpha = pars #Unpack model parameters\n",
    "    #Feed input parameters as dictionary to pico\n",
    "    input_dict = {\"As\": As,\"ns\": ns,\"tau\": tau,\"ombh2\":ombh2,\"omch2\":omch2,\"H0\":H0,\"omk\":omk}\n",
    "    output_dict = pico.get(**input_dict, force=True)\n",
    "    #Unpack the pico power spectrum output\n",
    "    tt = output_dict['dl_TT']\n",
    "    \n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_model(err, alpha):\n",
    "    \"\"\"\n",
    "    Evaluate the covariance matrix using a model where adjacent points have a correlation \n",
    "    scaled by the parameter alpha\n",
    "    \n",
    "    Runtime testing:\n",
    "    0.16 seconds with vectorization, 0.36 seconds with for loops\n",
    "    \n",
    "    Input:\n",
    "        err (arr)- error bars from each point in the WMAP data\n",
    "        alpha (float)- parameter controlling the correlation strength\n",
    "    Output:\n",
    "        C (arr)- covariance matrix of size [len(err),len(err)] for the correlated error model\n",
    "    \"\"\"    \n",
    "    #Compute each element in the covariance matrix\n",
    "    err_shift_1 = np.roll(err,-1) #Get the error shifted by one, to compute k=1 correlation terms\n",
    "    #Compute the diagonal and k=1 terms\n",
    "    diag_terms = err**2\n",
    "    diag_k1_terms = alpha*np.abs(err[0:-1]*err_shift_1[0:-1]) #Should I take the absolute value?\n",
    "    \n",
    "    #Cast the terms into matrix form and combine to get the final covariance matrix\n",
    "    C_diag = np.diag(np.array(diag_terms))\n",
    "    C_diag_k1 = np.diag(np.array(diag_k1_terms), k=1)\n",
    "    C_diag_km1 = np.diag(np.array(diag_k1_terms), k=-1)\n",
    "    C = C_diag + C_diag_k1 + C_diag_km1\n",
    "    \n",
    "    return C\n",
    "\n",
    "def log_likelihood_WMAP(theta, multipole, p_data, err, covariance_model):\n",
    "    \"\"\"\n",
    "    Evaluate the chi-sq metric of a PICO fit with a neighbour-correlation model or\n",
    "    an uncorrelated error model, given a set of model parameters stored in the array theta\n",
    "    \n",
    "    Return the log likelihood probability, which is equal to -chi_sq\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "        multipole (arr)- multipole moment data from WMAP\n",
    "        p_data (arr)- power spectrum data from WMAP\n",
    "        err (arr)- error bars on WMAP data points\n",
    "        covariance_model (str) - controls whether to calculate chi_sq using correlated or uncorrelated error model\n",
    "    Output:\n",
    "        chi_sq (float) - measure of goodness of fit, -chi_sq is proportional to log likelihood probability\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get model predictions from given params using PICO\n",
    "    pico_tt = get_PICO_spectrum(theta) #evaluate model\n",
    "    p_model = pico_tt[2:len(multipole)+2] #cut off the extra model points that extrapolate past where our multipole data ends\n",
    "    \n",
    "    if covariance_model == 'correlated':\n",
    "        alpha = theta[7] #Get the covariance scaling parameter\n",
    "        \n",
    "        #Get the components of the correlated chi-sq expression\n",
    "        At = np.array([p_data - p_model])\n",
    "        A = np.transpose(At)\n",
    "        C_inv = np.linalg.inv(get_cov_model(err, alpha))\n",
    "\n",
    "        chi_sq = np.dot(At, np.dot(C_inv,A))[0,0] #Evaluate the matrix multiplication of chi-squared terms\n",
    "\n",
    "    elif covariance_model == 'uncorrelated':\n",
    "        #Get the components of the uncorrelated chi-sq expression\n",
    "        x = np.asarray(p_data)\n",
    "        y = np.asarray(p_model)\n",
    "        error = np.asarray(err)\n",
    "        \n",
    "        chi_sq = sum((x-y)**2/error**2) #Evaluate chi-sq\n",
    "\n",
    "    return -chi_sq\n",
    "\n",
    "def log_prior_WMAP(theta):\n",
    "    \"\"\"\n",
    "    Evaluate the log prior probability function given model parameters\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "    Output:\n",
    "        Return 0.0 if params fall within constraints, else return -np.inf\n",
    "    \"\"\"\n",
    "    H0, ombh2, omch2, omk, tau, As, ns, alpha = theta #Unpack model parameters\n",
    "    \n",
    "    #Convert units of Omega params\n",
    "    h = H0/100\n",
    "    Omb = ombh2/(h**2)\n",
    "    Omde = omch2/(h**2)\n",
    "    \n",
    "    #Check that the params are allowed by our physical constraints\n",
    "    if 0. <= Omb <= 1. and 0. < Omde < 1. and -1.<=alpha<=1.:\n",
    "        return 0.0 # the constant doesn't matter since MCMCs only care about *ratios* of probabilities\n",
    "    return -np.inf # log(0) = -inf\n",
    "\n",
    "def log_post_WMAP_correlated(theta, multipole, p_data, err):\n",
    "    \"\"\"\n",
    "    Evaluate the log posterior probability function given WMAP data and \n",
    "    model parameters, using correlated error model\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "        multipole (arr)- multipole moment data from WMAP\n",
    "        p_data (arr)- power spectrum data from WMAP\n",
    "        err (arr)- error bars on WMAP data points\n",
    "    Output:\n",
    "        Return log likelihood probability if params fall within constraints, else return -np.inf\n",
    "        \n",
    "    \"\"\"\n",
    "    covariance_model = 'correlated'\n",
    "    \n",
    "    lp = log_prior_WMAP(theta) #Evaluate log prior\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf #Return -np.inf if params outside of constraints\n",
    "    \n",
    "    #If params inside constraints, lp = 0.0 and we reutrn the log likelihood\n",
    "    return lp + log_likelihood_WMAP(theta, multipole, p_data, err, covariance_model)\n",
    "\n",
    "def log_post_WMAP_uncorrelated(theta, multipole, p_data, err):\n",
    "    \"\"\"\n",
    "    Evaluate the log posterior probability function given WMAP data and \n",
    "    model parameters, using uncorrelated error model\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "        multipole (arr)- multipole moment data from WMAP\n",
    "        p_data (arr)- power spectrum data from WMAP\n",
    "        err (arr)- error bars on WMAP data points\n",
    "    Output:\n",
    "        Return log likelihood probability if params fall within constraints, else return -np.inf\n",
    "    \"\"\"\n",
    "    covariance_model = 'uncorrelated'\n",
    "    \n",
    "    lp = log_prior_WMAP(theta) #Evaluate log prior\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf #Return -np.inf if params outside of constraints\n",
    "    \n",
    "    #If params inside constraints, lp = 0.0 and we reutrn the log likelihood\n",
    "    return lp + log_likelihood_WMAP(theta, multipole, p_data, err, covariance_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the log_post_WMAP function run-time and output using a dummy set of parameter values\n",
    "pars_initialGuess=np.asarray([70,0.02,0.1,0.0,0.05,2e-9,0.97,0.07])\n",
    "\n",
    "#Test correlated errors model\n",
    "t1 = t.time()\n",
    "p_log_post = log_post_WMAP_correlated(pars_initialGuess, multipole, power, errPower)\n",
    "t2 = t.time()\n",
    "print(t2-t1,'seconds per log_post_WMAP call with correlated errors')\n",
    "print('Log Posterior value (correlated model) for the given params:',p_log_post)\n",
    "\n",
    "#Test uncorrelated errors model\n",
    "t1 = t.time()\n",
    "p_log_post = log_post_WMAP_uncorrelated(pars_initialGuess, multipole, power, errPower)\n",
    "t2 = t.time()\n",
    "print(t2-t1,'seconds per log_post_WMAP call with uncorrelated errors')\n",
    "print('Log Posterior value (uncorrelated model) for the given params:',p_log_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SNe_sample(x_data, flat_samples, ind):\n",
    "    \"\"\"\n",
    "    Prepare plot of SNe MCMC fit for animation\n",
    "    \n",
    "    Input:\n",
    "        x_data (arr)- x-axis values from data\n",
    "        flat_samples (arr)- parameters for each MCMC sample\n",
    "        ind (int) - index for selecting one sample\n",
    "    Output:\n",
    "        fig_name (str) - frame name that this figure was saved under, for use in reading into animation\n",
    "    \"\"\"\n",
    "    #Get the parameters from the specified sample, create the corresponding cosmo model, and evaluate mu\n",
    "    sample = flat_samples[ind]\n",
    "    H0, Om0, Ode0 = sample\n",
    "    cosmo = LambdaCDM(H0=H0, Om0=Om0, Ode0=Ode0) \n",
    "    y_model = mu_func(x_data, cosmo)\n",
    "    #Plot the fit for these parameters\n",
    "    plt.plot(x_data, y_model, alpha=0.01, color='red',zorder=2)\n",
    "    #Save the figure to add to the animation\n",
    "    fig_name = 'frame'+str(ind)+'.png'\n",
    "    plt.savefig(fig_name)\n",
    "    \n",
    "    return fig_name\n",
    "\n",
    "def plot_WMAP_sample(x_data, flat_samples, ind):\n",
    "    \"\"\"\n",
    "    Prepare plot of WMAP MCMC fit for animation\n",
    "    \n",
    "    Input:\n",
    "        x_data (arr)- x-axis values from data\n",
    "        flat_samples (arr)- parameters for each MCMC sample\n",
    "        ind (int) - index for selecting one sample\n",
    "    Output:\n",
    "        fig_name (str) - frame name that this figure was saved under, for use in reading into animation\n",
    "    \"\"\"\n",
    "    #Get the parameters and evaluate the corresponding PICO model\n",
    "    sample = flat_samples[ind]\n",
    "    y_model = get_PICO_spectrum(sample)\n",
    "    y_model = y_model[2:len(x_data)+2]\n",
    "    #Plot the fit for these parameters\n",
    "    #plt.plot(multipole,power)\n",
    "    plt.plot(x_data, y_model, alpha=0.01, color='red',zorder=2)\n",
    "    #Save the figure to add to the animation\n",
    "    fig_name = 'frame'+str(ind)+'.png'\n",
    "    plt.savefig(fig_name)\n",
    "    \n",
    "    return fig_name\n",
    "    \n",
    "def write_animation(fig_name_list, filename):\n",
    "    \"\"\"\n",
    "    Take a series of .png frames and animate them into a .gif. Save .gif to local working directory\n",
    "    \n",
    "    Input:\n",
    "        fig_name_list (arr): contains all of the frame filenames\n",
    "        filename (str): name under which the animation will be saved\n",
    "    \"\"\"\n",
    "    #build gif from the frames in the directory\n",
    "    with imageio.get_writer(filename, mode='I') as writer:\n",
    "        for fig_name in fig_name_list:\n",
    "            image = imageio.imread(fig_name)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    #clear the files from the directory files\n",
    "    for fig_name in set(fig_name_list):\n",
    "        os.remove(fig_name)\n",
    "        \n",
    "    print('Animation saved as ', filename)\n",
    "\n",
    "def MCMC_animation(sampler, x_data, y_data, y_err, dataset, filename, N_samples):\n",
    "    \"\"\"\n",
    "    Create an animation of the first N_samples of the MCMC fit\n",
    "    \n",
    "    Input:\n",
    "        sampler (obj): output of emcee with multiple walkers\n",
    "        x_data (arr)\n",
    "        y_data (arr)\n",
    "        y_err (arr): error bars on y_data\n",
    "        dataset (str): controls whether to animate SNe or WMAP data\n",
    "        filename (str): name under which the animation will be saved\n",
    "        N_samples (int): number of samples in single chain\n",
    "    \"\"\"\n",
    "    #Plot the original data for either SNe or WMAP\n",
    "    plt.figure(figsize=(7,7))\n",
    "    if dataset == 'SNe':\n",
    "        flat_samples = sampler.get_chain(flat=True)[:N_samples]\n",
    "        plt.plot(x_data, y_data,'.k')\n",
    "        #plt.errorbar(x_data, y_data, yerr=y_err, linestyle = 'None', fmt='.k',mec='black',mfc='black',ecolor='grey',zorder=1)\n",
    "        plt.xlabel(r'$z$')\n",
    "        plt.ylabel(r'$m-M (Mag)$')\n",
    "        plt.xscale('log')\n",
    "        plt.title('SCP Union 2.1 SNe Ia Data')\n",
    "    if dataset =='WMAP':\n",
    "        flat_samples = sampler.get_chain(discard=1000, thin =15, flat=True)[:N_samples]\n",
    "        plt.plot(multipole,power)\n",
    "        #plt.errorbar(wmap[:,0],wmap[:,1],wmap[:,2],fmt='*')\n",
    "        plt.xlabel('Multipole Moment')\n",
    "        plt.ylabel('Power Spectrum')\n",
    "        plt.title('WMAP Satellite 9-year CMB Data')\n",
    "    \n",
    "    #Plot each sample and save the plot frame as a .png\n",
    "    fig_name_list = []\n",
    "    for ind in range(N_samples):\n",
    "        if dataset == 'SNe':\n",
    "            fig_name = plot_SNe_sample(x_data, flat_samples, ind)\n",
    "        if dataset == 'WMAP':\n",
    "            fig_name = plot_WMAP_sample(x_data, flat_samples, ind)\n",
    "        #Store the frame filename\n",
    "        fig_name_list.append(fig_name)\n",
    "        \n",
    "    #Collect the .png frames and save them as a .gif animation\n",
    "    write_animation(fig_name_list, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcmc(log_posterior, args, ndim, nwalkers, initial_pos, backend_filename, do_burn_in, plot_convergence=True, num_iter=1000, burn_in=0,thin=0):\n",
    "    \"\"\"\n",
    "    Function which will either run MCMC with unknown burn-in time just until convergence (do_burn_in=True) \n",
    "    OR with known burn-in, thinning, and number of iterations. \n",
    "    \n",
    "    Input:\n",
    "        log_posterior (func): log posterior probability function to evaluate\n",
    "        args (arr): contains x_data, y_data, and y_err\n",
    "        ndim (int): number of model parameters to fit\n",
    "        nwalkers (int): number of emcee walkers to use\n",
    "        intial_pos (list): initial position in parameter space for each walker\n",
    "        backend_filename (str): name for backend file of results\n",
    "        do_burn_in (bool): controls whether to monitor convergence or specify number of iterations\n",
    "        plot_convergence (bool): controls whether to plot convergence-tracking figure\n",
    "        num_iter (int): specified number of iterations if do_burn_in==True\n",
    "        burn_in (int): number of steps to discard as burn-in\n",
    "        thin (int): thinning rate for chain. If thin=n, keep only every nth sample\n",
    "        \n",
    "    \"\"\"\n",
    "    # Set up the backend to store chain results in case of crashing or infinite looping\n",
    "    backend = emcee.backends.HDFBackend(backend_filename)\n",
    "    backend.reset(nwalkers, ndim) #reset if it's already been created\n",
    "\n",
    "    # Initialize the sampler\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=args, backend=backend)\n",
    "    \n",
    "    if(do_burn_in):\n",
    "        #run until converged , with the option of plotting convergence\n",
    "        autocorr, tau = mcmc_burn_in(sampler,plot_convergence)\n",
    "        \n",
    "        #calculate the burn-in and thin parameters\n",
    "        burn_in = int(2 * np.max(tau))\n",
    "        thin = int(0.5 * np.min(tau))\n",
    "        \n",
    "        print(\"Mean autocorrelation time: {0:.3f} steps\".format(np.mean(tau)))\n",
    "        print(\"burn-in: {0}\".format(burn_in))\n",
    "        print(\"thin: {0}\".format(thin))\n",
    "    else:\n",
    "        #run with specified number of iterations\n",
    "        flat_samples = sampler.run_mcmc(initial_pos, num_iter, progress=True)\n",
    "        \n",
    "    flat_samples = sampler.get_chain(discard=burn_in, flat=True, thin=thin) \n",
    "    return sampler, flat_samples , burn_in , thin\n",
    "\n",
    "def plot_convergence(autocorr,index):\n",
    "    \"\"\"\n",
    "    Plot the convergence-tracking figure of autocorrelation time vs chain length\n",
    "    \n",
    "    Input:\n",
    "        autocorr (arr)- autocorrelation times as a function of chain length\n",
    "        index (int)- Number of autocorrelation time measurements to plot\n",
    "    \"\"\"\n",
    "    n = 100 * np.arange(1, index + 1)\n",
    "    y = autocorr[:index]\n",
    "    plt.plot(n, n / 100.0, \"--k\")\n",
    "    plt.plot(n, y)\n",
    "    plt.xlim(0, n.max())\n",
    "    plt.ylim(0, y.max() + 0.1 * (y.max() - y.min()))\n",
    "    plt.xlabel(\"number of steps\")\n",
    "    plt.ylabel(r\"mean $\\hat{\\tau}$\")\n",
    "    plt.show()\n",
    "    \n",
    "def mcmc_burn_in(sampler,plot,max_n=10000000):\n",
    "    \"\"\"\n",
    "    Note: The following code is adapted from an emcee tutorial\n",
    "    \n",
    "    Run mcmc for maximum 100,000 steps, or until converged\n",
    "    \n",
    "    Input:\n",
    "        sampler (obj)- output of emcee with multiple walkers\n",
    "    Output:\n",
    "        autocorr (arr)- autocorrelation times as a function of chain length\n",
    "        tau (float) - autocorrelation time\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll track how the average autocorrelation time estimate changes\n",
    "    index = 0\n",
    "    autocorr = np.empty(max_n)\n",
    "\n",
    "    # This will be useful to testing convergence\n",
    "    old_tau = np.inf\n",
    "\n",
    "    # Now we'll sample for up to max_n steps\n",
    "    for sample in sampler.sample(initial_pos, iterations=max_n, store = True , progress=True):\n",
    "        # Only check convergence every 100 steps\n",
    "        if sampler.iteration % 100:\n",
    "            continue\n",
    "\n",
    "        # Compute the autocorrelation time so far\n",
    "        # Using tol=0 means that we'll always get an estimate even if it isn't trustworthy\n",
    "        tau = sampler.get_autocorr_time(tol=0)\n",
    "        autocorr[index] = np.mean(tau)\n",
    "        index += 1\n",
    "\n",
    "        # Check convergence\n",
    "        converged = np.all(tau * 100 < sampler.iteration)\n",
    "        converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "        if converged:\n",
    "            break\n",
    "        old_tau = tau\n",
    "    \n",
    "    tau = sampler.get_autocorr_time()\n",
    "    \n",
    "    if(plot):\n",
    "        plot_convergence(autocorr,index)\n",
    "    \n",
    "    return autocorr, tau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WMAP MCMC Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 8 # number of parameters\n",
    "nwalkers = 25 #number of walkers\n",
    "\n",
    "#set up initial param guesses\n",
    "H0_initial = 70\n",
    "ombh2_initial =0.02\n",
    "omch2_initial = 0.1\n",
    "omk_initial = 0\n",
    "tau_initial = 0.05\n",
    "As_initial = 2e-9\n",
    "ns_initial = 0.97\n",
    "alpha_initial = 0.07\n",
    "pars_initialGuess=np.asarray([H0_initial, ombh2_initial, omch2_initial, omk_initial, tau_initial, As_initial, ns_initial, alpha_initial])\n",
    "\n",
    "initial_pos = pars_initialGuess + 0.01 * np.random.randn(nwalkers, ndim) #gaussian ball of walkers\n",
    "\n",
    "args = (multipole, power, errPower)\n",
    "\n",
    "backend_filename = \"wmap_chain.h5\"\n",
    "backend = emcee.backends.HDFBackend(backend_filename)\n",
    "backend.reset(nwalkers, ndim) #reset if it's already been created\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_post_WMAP_uncorrelated, args=args, backend=backend);\n",
    "sampler.run_mcmc(initial_pos, 1000000, progress=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_samples_uncoor = sampler.get_chain(discard=1000, thin =15, flat=True)\n",
    "\n",
    "# f, axes = plt.subplots(8, figsize=(10, 7), sharex=True)\n",
    "# samples = sampler.get_chain()\n",
    "# #labels = [\"H0\", \"Om0\", \"Ode0\"]\n",
    "# for i in range(ndim):\n",
    "#     ax = axes[i]\n",
    "#     ax.plot(samples[:, 0, i], alpha=0.3)\n",
    "#     ax.set_xlim(0, len(samples))\n",
    "#     #ax.set_ylabel(labels[i])\n",
    "#     #ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "# axes[-1].set_xlabel(\"Step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check convergences for correlated\n",
    "# backend_filename_corr = \"wmap_chain_corr.h5\"\n",
    "# sampler_WMAP_corr, flat_samples_WMAP_corr, burn_in_WMAP_corr, thin_WMAP_corr = run_mcmc(log_post_WMAP_correlated, args, ndim, nwalkers, initial_pos, backend_filename_corr, True)\n",
    "\n",
    "#run mcmc with burn in \n",
    "#sampler_WMAP_corr,flat_samples_WMAP_corr, burn_in_WMAP_corr, thin_WMAP_corr = run_mcmc(log_post_WMAP_correlated, args, ndim, nwalkers, initial_pos, backend_filename, do_burn_in=False, num_iter=50000, burn_in=burn_in_WMAP,thin=thin_WMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check convergences for uncorrelated\n",
    "# backend_filename_uncorr = \"wmap_chain_uncorr.h5\"\n",
    "# sampler_WMAP_uncorr, flat_samples_WMAP_uncorr, burn_in_WMAP_uncorr, thin_WMAP_uncorr = run_mcmc(log_post_WMAP_uncorrelated, args, ndim, nwalkers, initial_pos, backend_filename_uncorr, True)\n",
    "\n",
    "#run mcmc with burn in \n",
    "#sampler_WMAP_uncorr,flat_samples_WMAP_uncorr, burn_in_WMAP_uncorr, thin_WMAP_uncorr = run_mcmc(log_post_WMAP_uncorrelated, args, ndim, nwalkers, initial_pos, backend_filename, do_burn_in=False, num_iter=50000, burn_in=burn_in_WMAP,thin=thin_WMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = emcee.backends.HDFBackend(backend_filename_uncorr)\n",
    "\n",
    "# tau = reader.get_autocorr_time()\n",
    "# burnin = int(2 * np.max(tau))\n",
    "# thin = int(0.5 * np.min(tau))\n",
    "# samples = reader.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "# log_prob_samples = reader.get_log_prob(discard=burnin, flat=True, thin=thin)\n",
    "# log_prior_samples = reader.get_blobs(discard=burnin, flat=True, thin=thin)\n",
    "\n",
    "# print(\"burn-in: {0}\".format(burnin))\n",
    "# print(\"thin: {0}\".format(thin))\n",
    "# print(\"flat chain shape: {0}\".format(samples.shape))\n",
    "# print(\"flat log prob shape: {0}\".format(log_prob_samples.shape))\n",
    "# print(\"flat log prior shape: {0}\".format(log_prior_samples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot movie for correlated\n",
    "# filename = 'WMAP_MCMC_corr_animation.gif'\n",
    "# dataset = 'WMAP'\n",
    "# N_samples = 100\n",
    "# #Create animation of MCMC fitting\n",
    "# MCMC_animation(sampler_WMAP_corr, multipole, power, errPower, dataset, filename, N_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot movie for uncorrelated\n",
    "filename = 'WMAP_MCMC_uncorr_animation.gif'\n",
    "dataset = 'WMAP'\n",
    "N_samples = 100\n",
    "#Create animation of MCMC fitting\n",
    "MCMC_animation(sampler, multipole, power, errPower, dataset, filename, N_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Probability Function for SNe Ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_func(z, cosmo):\n",
    "    \"\"\"\n",
    "    Given a redshift value z and universe model cosmo, convert to luminosity distance and calculate \n",
    "    the distance modulus mu (aka m-M)\n",
    "    \n",
    "    Input:\n",
    "        z (float): redshift value\n",
    "        cosmo (obj): LambdaCDM cosmology model\n",
    "    Output:\n",
    "        mu (float): distance modulus, aka m-M\n",
    "    \"\"\"\n",
    "    D_L = cosmo.luminosity_distance(z).value #convert z to luminosity distance\n",
    "    mu = 5*np.log10(D_L)+25 #calculate mu\n",
    "    return mu\n",
    "\n",
    "def log_likelihood_sn(theta, z, mu_data, mu_err):\n",
    "    \"\"\"\n",
    "    Evaluate the log likelihood of a SNe Ia fit with an uncorrelated error \n",
    "    model given a set of model parameters stored in the array theta\n",
    "    \n",
    "    Input:\n",
    "        theta - array of model params\n",
    "        z - array of redshift data from SNe Ia\n",
    "        mu_data - array of mu data from SNe Ia\n",
    "        mu_err - array of error bars on mu_data\n",
    "    Output:\n",
    "        Return the log likelihood probability, which is equal to -chi_sq\n",
    "    \"\"\"\n",
    "    #Get the parameters and create the corresponding cosmo model\n",
    "    H0, Om0, Ode0 = theta\n",
    "    cosmo = LambdaCDM(H0=H0, Om0=Om0, Ode0=Ode0)\n",
    "    #Evaluate the model at the data point z values\n",
    "    mu_model = mu_func(z, cosmo)\n",
    "    \n",
    "    sigma2 = mu_err ** 2\n",
    "    return -0.5 * np.sum((mu_data - mu_model) ** 2 / sigma2 + np.log(2*np.pi*sigma2)) # the 2pi factor doesn't affect the shape\n",
    "\n",
    "def log_prior_sn(theta):\n",
    "    \"\"\"\n",
    "    Evaluate the log prior probability function given model parameters\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "    Output:\n",
    "        Return 0.0 if params fall within constraints, else return -np.inf\n",
    "    \"\"\"\n",
    "    H0, Om0, Ode0 = theta\n",
    "    #Check that the params are allowed by our physical constraints\n",
    "    if 0. <= Om0 <= 1. and 0. < Ode0 < 1.:\n",
    "        return 0.0 # the constant doesn't matter since MCMCs only care about *ratios* of probabilities\n",
    "    return -np.inf # log(0) = -inf\n",
    "\n",
    "def log_post_sn(theta, z, mu_data, mu_err):\n",
    "    \"\"\"\n",
    "    Evaluate the log posterior probability function given SNe Ia data and model parameters\n",
    "    \n",
    "    Input:\n",
    "        theta (arr)- model params\n",
    "        z (arr)- redshift data from SNe Ia\n",
    "        mu_data (arr)- mu data from SNe Ia\n",
    "        mu_err (arr)- error bars on mu_data\n",
    "    Output:\n",
    "        Return log likelihood probability if params fall within constraints, else return -np.inf\n",
    "        \n",
    "    \"\"\"\n",
    "    lp = log_prior_sn(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood_sn(theta, z, mu_data, mu_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNe Ia MCMC Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check tau_f to tune MCMC, show corner plots of results\n",
    "#Plot the posterior fit with the data\n",
    "\n",
    "sn_z,sn_dm,sn_dm_err = np.loadtxt(\"SCPUnion2.1_mu_vs_z.txt\",delimiter=\"\\t\",skiprows=5, usecols = (1,2,3),unpack=True)\n",
    "\n",
    "\n",
    "ndim = 3 # number of parameters\n",
    "nwalkers = 16\n",
    "\n",
    "#set up initial guesses\n",
    "H0_initial = 70\n",
    "Omc_initial =0.7\n",
    "Omm_initial = 0.3\n",
    "pars_initialGuess = np.asarray([H0_initial, ombh2_initial, omch2_initial])\n",
    "\n",
    "initial_pos = pars_initialGuess + 0.01 * np.random.randn(nwalkers, ndim) #gaussian ball of walkers\n",
    "\n",
    "args = (sn_z,sn_dm,sn_dm_err)\n",
    "\n",
    "backend_filename = \"SNe_chain.h5\"\n",
    "\n",
    "sampler_SNe, flat_samples_SNe, burn_in_SNe, thin_SNe = run_mcmc(log_post_sn, args, ndim, nwalkers, initial_pos, backend_filename, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_SNe, flat_samples_SNe, burn_in_SNe, thin_SNe = run_mcmc(log_post_sn, args, ndim, nwalkers, initial_pos, backend_filename, do_burn_in=False, num_iter=50000, burn_in=burn_in_SNe,thin=thin_SNe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw data plot\n",
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(sn_z, sn_dm, yerr=sn_dm_err, fmt='.k', ecolor='gray')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel(r'$m-M$ (mag)')\n",
    "ax.set_xlabel(r'$z$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNe MCMC Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SNe_MCMC_animation.gif'\n",
    "dataset = 'SNe'\n",
    "N_samples = 100\n",
    "#Create animation of MCMC fitting\n",
    "MCMC_animation(sampler_SNe, sn_z, sn_dm, sn_dm_err, dataset, filename, N_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay comparison of WMAP and SNe Ia Posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay the posteriors for the omegas to compare between the two measurements\n",
    "#Maybe include best fit values from Planck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNE\n",
    "#Ho, 0mO , 0de \n",
    "#Calculate posterior for omega_k = 1 - omega_m - omega_de\n",
    "Ho_fits_SNE = flat_samples_SNe.T[0]\n",
    "Om0_fits_SNE = flat_samples_SNe.T[1]\n",
    "Ode0_fits_SNE = flat_samples_SNe.T[2]\n",
    "curvature = 1 - Om0_fits_SNE - Ode0_fits_SNE\n",
    "\n",
    "#get new flat_samples with new parameter, omega k\n",
    "Ho_fits_SNE = np.reshape(Ho_fits_SNE, (len(Ho_fits_SNE), 1))\n",
    "Om0_fits_SNE = np.reshape(Om0_fits_SNE, (len(Om0_fits_SNE), 1))\n",
    "Ode0_fits_SNE = np.reshape(Ode0_fits_SNE, (len(Ode0_fits_SNE), 1))\n",
    "curvature_fits = np.reshape(curvature, (len(curvature), 1))\n",
    "flat_samples_SNE_k = np.hstack((Ho_fits_SNE,Om0_fits_SNE,Ode0_fits_SNE,curvature_fits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WMAP corr\n",
    "# #H0, ombh2, omch2, omk, tau, As, ns, alpha\n",
    "# Ho_fits_WMAP_corr = flat_samples_WMAP_corr.T[0]\n",
    "# ombh2_WMAP_corr = flat_samples_WMAP_corr.T[1]\n",
    "# omch2_WMAP_corr = flat_samples_WMAP_corr.T[2] \n",
    "# omk_WMAP_corr = flat_samples_WMAP_corr.T[3]\n",
    "\n",
    "# #if we ever need them \n",
    "# tau_WMAP_corr = flat_samples_WMAP_corr.T[4]\n",
    "# As_WMAP_corr = flat_samples_WMAP_corr.T[5]\n",
    "# ns_WMAP_corr = flat_samples_WMAP_corr.T[6]\n",
    "# alpha_WMAP_corr = flat_samples_WMAP_corr.T[7]\n",
    "\n",
    "# h_fit_WMAP_corr = Ho_fits_WMAP_corr/100\n",
    "# omb_WMAP_corr = ombh2_WMAP_corr/(h**2) #baryon\n",
    "# omc_WMAP_corr = omch2_WMAP_corr/(h**2) #dark matter\n",
    "\n",
    "\n",
    "# Om0_WMAP_corr = omb_WMAP_corr + omc_WMAP_corr # add them together to get mass density\n",
    "# Ode0_WMAP_corr = 1 - Om0_WMAP_corr - omk_WMAP_corr # get dark energy from curvature const\n",
    "\n",
    "# #get new flat_samples with new parameter, omega k\n",
    "# Ho_fits_WMAP_corr = np.reshape(Ho_fits_WMAP_corr, (len(Ho_fits_WMAP_corr), 1))\n",
    "# Om0_fits_WMAP_corr = np.reshape(Om0_WMAP_corr, (len(Om0_WMAP_corr), 1))\n",
    "# Ode0_fits_WMAP_corr = np.reshape(Ode0_WMAP_corr, (len(Ode0_WMAP_corr), 1))\n",
    "# curv_fits_WMAP_corr = np.reshape(omk_WMAP_corr (len(omk_WMAP_corr), 1))\n",
    "# flat_samples_WMAP_k_corr = np.hstack((Ho_fits_WMAP_corr,Om0_fits_WAMP_corr,Ode0_fits_WMAP_corr,curv_fits_WMAP_corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WMAP uncorr\n",
    "#H0, ombh2, omch2, omk, tau, As, ns, alpha\n",
    "flat_samples_WMAP_uncorr = sampler.get_chain(discard=1000, thin =15, flat=True)\n",
    "Ho_fits_WMAP_uncorr = flat_samples_WMAP_uncorr.T[0]\n",
    "ombh2_WMAP_uncorr = flat_samples_WMAP_uncorr.T[1]\n",
    "omch2_WMAP_uncorr = flat_samples_WMAP_uncorr.T[2] \n",
    "omk_WMAP_uncorr = flat_samples_WMAP_uncorr.T[3]\n",
    "\n",
    "#if we ever need them \n",
    "tau_WMAP_uncorr = flat_samples_WMAP_uncorr.T[4]\n",
    "As_WMAP_uncorr = flat_samples_WMAP_uncorr.T[5]\n",
    "ns_WMAP_uncorr = flat_samples_WMAP_uncorr.T[6]\n",
    "alpha_WMAP_uncorr = flat_samples_WMAP_uncorr.T[7]\n",
    "\n",
    "h_fit_WMAP_uncorr = Ho_fits_WMAP_uncorr/100\n",
    "omb_WMAP_uncorr = ombh2_WMAP_uncorr/(h_fit_WMAP_uncorr**2) #baryon\n",
    "omc_WMAP_uncorr = omch2_WMAP_uncorr/(h_fit_WMAP_uncorr**2) #dark matter\n",
    "\n",
    "\n",
    "Om0_WMAP_uncorr = omb_WMAP_uncorr + omc_WMAP_uncorr # add them together to get mass density\n",
    "Ode0_WMAP_uncorr = 1 - Om0_WMAP_uncorr - omk_WMAP_uncorr # get dark energy from curvature const\n",
    "\n",
    "#get new flat_samples with new parameter, omega k\n",
    "Ho_fits_WMAP_uncorr = np.reshape(Ho_fits_WMAP_uncorr, (len(Ho_fits_WMAP_uncorr), 1))\n",
    "Om0_fits_WMAP_uncorr = np.reshape(Om0_WMAP_uncorr, (len(Om0_WMAP_uncorr), 1))\n",
    "Ode0_fits_WMAP_uncorr = np.reshape(Ode0_WMAP_uncorr, (len(Ode0_WMAP_uncorr), 1))\n",
    "curv_fits_WMAP_uncorr = np.reshape(omk_WMAP_uncorr, (len(omk_WMAP_uncorr), 1))\n",
    "flat_samples_WMAP_k_uncorr = np.hstack((Ho_fits_WMAP_uncorr,Om0_fits_WMAP_uncorr,Ode0_fits_WMAP_uncorr,curv_fits_WMAP_uncorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corner plot SNE\n",
    "#Create a corner plot of the posterior for Om0, Ode0, Ok0\n",
    "labels = [\"H0\", \"Om0\", \"Ode0\",\"Curvature\"]\n",
    "fig1 = corner.corner(flat_samples_SNE_k, bins = 50, labels=labels, show_titles=True,quantiles=[0.16, 0.5, 0.84]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corner plot WMAP\n",
    "#Create a corner plot of the posterior for Om0, Ode0, Ok0\n",
    "labels = [\"H0\", \"Om0\", \"Ode0\",\"Curvature\"]\n",
    "fig1 = corner.corner(flat_samples_WMAP_k_corr, bins = 50, labels=labels, show_titles=True,quantiles=[0.16, 0.5, 0.84]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corner plot WMAP\n",
    "#Create a corner plot of the posterior for Om0, Ode0, Ok0\n",
    "labels = [\"H0\", \"Om0\", \"Ode0\",\"Curvature\"]\n",
    "fig1 = corner.corner(flat_samples_WMAP_k_uncorr, bins = 50, labels=labels, show_titles=True,quantiles=[0.16, 0.5, 0.84]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay the posteriors for the omegas to compare between the two measurements\n",
    "#Maybe include best fit values from Planck?\n",
    "\n",
    "corner.hist2d(Om0_fits_SNE,Ode0_fits_SNE)\n",
    "corner.hist2d(Om0_fits_WMAP_corr,Ode0_fits_WMAP_corr)\n",
    "plt.xlabel(\"Omega_c\");\n",
    "plt.ylabel(\" Omega_Λ\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay the posteriors for the omegas to compare between the two measurements\n",
    "#Maybe include best fit values from Planck?\n",
    "\n",
    "corner.hist2d(Om0_fits_SNE,Ode0_fits_SNE)\n",
    "corner.hist2d(Om0_fits_WMAP_uncorr,Ode0_fits_WMAP_uncorr)\n",
    "plt.xlabel(\"Omega_m\");\n",
    "plt.ylabel(\" Omega_Λ\");\n",
    "plt.title(\"uncorrelated CMB & SNE\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
